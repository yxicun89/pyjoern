"""
ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ— ã‚°ãƒ©ãƒ•è¦–è¦šåŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ 
åˆå¿ƒè€…ã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’æ®µéšçš„ã«è¡¨ç¤º
"""

from pyjoern import parse_source, fast_cfgs_from_source
import networkx as nx
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.patches import FancyBboxPatch
import os
from datetime import datetime

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

class FlowVisualizer:
    def __init__(self):
        self.output_dir = "flow_analysis_results"
        self.ensure_output_dir()
        
    def ensure_output_dir(self):
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"ğŸ“ çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: {self.output_dir}")
    
    def analyze_control_flow(self, source_file):
        """åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚’æ®µéšçš„ã«è§£æãƒ»èª¬æ˜"""
        print("=" * 80)
        print("ğŸ” ãƒ—ãƒ­ã‚°ãƒ©ãƒ åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼è§£æ - ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰")
        print("=" * 80)
        print(f"ğŸ“„ è§£æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {source_file}")
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬æƒ…å ±
        print("\nğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—1: ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®æ§‹é€ ã‚’ç†è§£ã™ã‚‹")
        print("-" * 50)
        
        try:
            with open(source_file, 'r', encoding='utf-8') as f:
                source_lines = f.readlines()
            print(f"âœ… ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å®Œäº†")
            print(f"   ğŸ“ ç·è¡Œæ•°: {len(source_lines)} è¡Œ")
            print(f"   ğŸ“ æœ€åˆã®æ•°è¡Œ:")
            for i, line in enumerate(source_lines[:5], 1):
                print(f"     {i:2d}: {line.rstrip()}")
            if len(source_lines) > 5:
                print(f"     ... (æ®‹ã‚Š {len(source_lines) - 5} è¡Œ)")
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: PyJoernã§ã®è§£æ
        print(f"\nğŸ”¬ ã‚¹ãƒ†ãƒƒãƒ—2: PyJoernã«ã‚ˆã‚‹è©³ç´°è§£æ")
        print("-" * 50)
        
        try:
            functions = parse_source(source_file)
            print(f"âœ… PyJoernè§£æå®Œäº†")
            print(f"   ğŸ¯ ç™ºè¦‹ã•ã‚ŒãŸé–¢æ•°æ•°: {len(functions)}")
            
            for func_name in functions.keys():
                print(f"   ğŸ“‹ é–¢æ•°: '{func_name}'")
                
        except Exception as e:
            print(f"âŒ PyJoernè§£æã‚¨ãƒ©ãƒ¼: {e}")
            return
        
        # ã‚¹ãƒ†ãƒƒãƒ—3: å„é–¢æ•°ã®è©³ç´°è§£æ
        for func_name, func_obj in functions.items():
            self.analyze_single_function(func_name, func_obj, source_file)
    
    def analyze_single_function(self, func_name, func_obj, source_file):
        """å˜ä¸€é–¢æ•°ã®è©³ç´°è§£æ"""
        print(f"\nğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—3: é–¢æ•° '{func_name}' ã®è©³ç´°è§£æ")
        print("-" * 50)
        
        # åŸºæœ¬æƒ…å ±
        print(f"ğŸ“ é–¢æ•°ã®ä½ç½®æƒ…å ±:")
        print(f"   é–‹å§‹è¡Œ: {func_obj.start_line}")
        print(f"   çµ‚äº†è¡Œ: {func_obj.end_line}")
        print(f"   è¡Œæ•°: {func_obj.end_line - func_obj.start_line + 1}")
        
        # CFGè§£æ
        if hasattr(func_obj, 'cfg') and func_obj.cfg:
            self.analyze_cfg_flow(func_name, func_obj.cfg, source_file)
        
        # å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³ã®ç”Ÿæˆ
        self.create_execution_flow_diagram(func_name, func_obj, source_file)
    
    def analyze_cfg_flow(self, func_name, cfg, source_file):
        """CFGã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’è©³ç´°è§£æ"""
        print(f"\nğŸ“Š CFG (åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•) è§£æ:")
        print(f"   ğŸ”¢ ãƒãƒ¼ãƒ‰æ•°: {len(cfg.nodes())} å€‹")
        print(f"   ğŸ”— ã‚¨ãƒƒã‚¸æ•°: {len(cfg.edges())} å€‹")
        
        # ãƒãƒ¼ãƒ‰ã®åˆ†é¡ã¨èª¬æ˜
        entry_nodes = []
        exit_nodes = []
        merge_nodes = []
        regular_nodes = []
        
        print(f"\nğŸ“‹ ãƒãƒ¼ãƒ‰ã®è©³ç´°åˆ†æ:")
        for i, node in enumerate(cfg.nodes(), 1):
            node_type = "é€šå¸¸ãƒãƒ¼ãƒ‰"
            
            if hasattr(node, 'is_entrypoint') and node.is_entrypoint:
                entry_nodes.append(node)
                node_type = "ğŸš€ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ (ãƒ—ãƒ­ã‚°ãƒ©ãƒ é–‹å§‹)"
            elif hasattr(node, 'is_exitpoint') and node.is_exitpoint:
                exit_nodes.append(node)
                node_type = "ğŸ ã‚¨ã‚°ã‚¸ãƒƒãƒˆãƒã‚¤ãƒ³ãƒˆ (ãƒ—ãƒ­ã‚°ãƒ©ãƒ çµ‚äº†)"
            elif hasattr(node, 'is_merged_node') and node.is_merged_node:
                merge_nodes.append(node)
                node_type = "ğŸ”„ ãƒãƒ¼ã‚¸ãƒãƒ¼ãƒ‰ (è¤‡æ•°ã®æµã‚ŒãŒåˆæµ)"
            else:
                regular_nodes.append(node)
            
            addr = getattr(node, 'addr', 'N/A')
            stmt_count = len(node.statements) if hasattr(node, 'statements') and node.statements else 0
            
            print(f"   ãƒãƒ¼ãƒ‰{i} (Block {addr}): {node_type}")
            print(f"     ğŸ’¬ å«ã¾ã‚Œã‚‹æ–‡ã®æ•°: {stmt_count}")
            
            # ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã®è©³ç´°
            if hasattr(node, 'statements') and node.statements:
                print(f"     ğŸ“ å®Ÿè¡Œã•ã‚Œã‚‹å‡¦ç†:")
                for j, stmt in enumerate(node.statements[:3], 1):  # æœ€åˆã®3ã¤ã®ã¿
                    stmt_str = str(stmt)
                    if len(stmt_str) > 50:
                        stmt_str = stmt_str[:47] + "..."
                    print(f"       {j}. {stmt_str}")
                if len(node.statements) > 3:
                    print(f"       ... (ä»– {len(node.statements) - 3} å€‹ã®å‡¦ç†)")
        
        # ãƒ•ãƒ­ãƒ¼åˆ†æçµæœã®è¦ç´„
        print(f"\nğŸ“ˆ å®Ÿè¡Œãƒ•ãƒ­ãƒ¼è¦ç´„:")
        print(f"   ğŸš€ é–‹å§‹ãƒã‚¤ãƒ³ãƒˆ: {len(entry_nodes)} å€‹")
        print(f"   ğŸ çµ‚äº†ãƒã‚¤ãƒ³ãƒˆ: {len(exit_nodes)} å€‹") 
        print(f"   ğŸ”„ åˆ†å²åˆæµç‚¹: {len(merge_nodes)} å€‹")
        print(f"   ğŸ“‹ å‡¦ç†ãƒ–ãƒ­ãƒƒã‚¯: {len(regular_nodes)} å€‹")
        
        # å®Ÿè¡Œãƒ‘ã‚¹ã®åˆ†æ
        self.analyze_execution_paths(cfg, entry_nodes, exit_nodes)
    
    def analyze_execution_paths(self, cfg, entry_nodes, exit_nodes):
        """å®Ÿè¡Œå¯èƒ½ãªãƒ‘ã‚¹ã‚’åˆ†æ"""
        print(f"\nğŸ›£ï¸ å®Ÿè¡Œãƒ‘ã‚¹åˆ†æ:")
        
        if not entry_nodes or not exit_nodes:
            print("   âš ï¸ ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¾ãŸã¯ã‚¨ã‚°ã‚¸ãƒƒãƒˆãƒãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        path_count = 0
        for entry in entry_nodes:
            for exit in exit_nodes:
                if nx.has_path(cfg, entry, exit):
                    path_count += 1
                    try:
                        path = nx.shortest_path(cfg, entry, exit)
                        print(f"   ãƒ‘ã‚¹{path_count}: {len(path)} ã‚¹ãƒ†ãƒƒãƒ—")
                        print(f"     ğŸš€ é–‹å§‹ â†’ ", end="")
                        
                        for i, node in enumerate(path):
                            addr = getattr(node, 'addr', 'N/A')
                            if i < len(path) - 1:
                                print(f"Block{addr} â†’ ", end="")
                            else:
                                print(f"Block{addr} ğŸ çµ‚äº†")
                                
                    except Exception as e:
                        print(f"     âŒ ãƒ‘ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
        
        if path_count == 0:
            print("   âš ï¸ å®Ÿè¡Œå¯èƒ½ãªãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            print(f"   ğŸ“Š ç·å®Ÿè¡Œãƒ‘ã‚¹æ•°: {path_count} é€šã‚Š")
    
    def create_execution_flow_diagram(self, func_name, func_obj, source_file):
        """å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³ã‚’ä½œæˆ"""
        print(f"\nğŸ¨ å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³ã‚’ç”Ÿæˆä¸­...")
        
        cfg = func_obj.cfg
        if not cfg or len(cfg.nodes()) == 0:
            print("   âŒ CFGãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return
        
        # å›³ã®ã‚µã‚¤ã‚ºã‚’å‹•çš„ã«èª¿æ•´
        node_count = len(cfg.nodes())
        fig_width = max(14, node_count * 2)
        fig_height = max(10, node_count * 1.5)
        
        plt.figure(figsize=(fig_width, fig_height))
        
        # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—ï¼ˆéšå±¤çš„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’å„ªå…ˆï¼‰
        try:
            pos = nx.nx_agraph.graphviz_layout(cfg, prog='dot')
        except:
            pos = nx.spring_layout(cfg, k=3, iterations=100)
        
        # ãƒãƒ¼ãƒ‰ã®è‰²ã¨ãƒ©ãƒ™ãƒ«ä½œæˆ
        node_colors = []
        labels = {}
        node_types = {}
        
        for node in cfg.nodes():
            addr = getattr(node, 'addr', 'N/A')
            
            # ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—ã®åˆ¤å®šã¨è‰²è¨­å®š
            if hasattr(node, 'is_entrypoint') and node.is_entrypoint:
                node_colors.append('#90EE90')  # æ˜ã‚‹ã„ç·‘
                node_types[node] = "START"
                labels[node] = f">> START\nBlock {addr}"
            elif hasattr(node, 'is_exitpoint') and node.is_exitpoint:
                node_colors.append('#FFB6C1')  # æ˜ã‚‹ã„ãƒ”ãƒ³ã‚¯
                node_types[node] = "END"
                labels[node] = f"<< END\nBlock {addr}"
            elif hasattr(node, 'is_merged_node') and node.is_merged_node:
                node_colors.append('#FFD700')  # ã‚´ãƒ¼ãƒ«ãƒ‰
                node_types[node] = "MERGE"
                labels[node] = f"<> MERGE\nBlock {addr}"
            else:
                node_colors.append('#87CEEB')  # ã‚¹ã‚«ã‚¤ãƒ–ãƒ«ãƒ¼
                node_types[node] = "PROCESS"
                labels[node] = f"[] PROCESS\nBlock {addr}"
            
            # ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’è¿½åŠ 
            if hasattr(node, 'statements') and node.statements:
                stmt_count = len(node.statements)
                labels[node] += f"\n({stmt_count} stmts)"
                
                # ä¸»è¦ãªå‡¦ç†ã‚’è¡¨ç¤º
                if node.statements:
                    first_stmt = str(node.statements[0])
                    if len(first_stmt) > 25:
                        first_stmt = first_stmt[:22] + "..."
                    labels[node] += f"\n{first_stmt}"
        
        # ã‚¨ãƒƒã‚¸ã®æç”»ï¼ˆãƒ•ãƒ­ãƒ¼æ–¹å‘ã‚’å¼·èª¿ï¼‰
        nx.draw_networkx_edges(cfg, pos, 
                              edge_color='#666666', 
                              arrows=True, 
                              arrowsize=25, 
                              arrowstyle='-|>',
                              width=2,
                              alpha=0.8)
        
        # ãƒãƒ¼ãƒ‰ã®æç”»
        nx.draw_networkx_nodes(cfg, pos, 
                              node_color=node_colors,
                              node_size=4000,
                              alpha=0.9,
                              edgecolors='black',
                              linewidths=2)
        
        # ãƒ©ãƒ™ãƒ«ã®æç”»
        nx.draw_networkx_labels(cfg, pos, labels, 
                               font_size=10, 
                               font_weight='bold',
                               font_family='monospace')
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ¡ã‚¿æƒ…å ±
        plt.title(f"Execution Flow: {func_name} (File: {source_file})\n"
                 f"Nodes: {len(cfg.nodes())}, Edges: {len(cfg.edges())}, "
                 f"Complexity: {'Low' if len(cfg.nodes()) <= 5 else 'Medium' if len(cfg.nodes()) <= 10 else 'High'}", 
                 fontsize=16, fontweight='bold', pad=30)
        
        # è©³ç´°ãªå‡¡ä¾‹
        legend_elements = [
            mpatches.Patch(color='#90EE90', label='START (Program Start)'),
            mpatches.Patch(color='#FFB6C1', label='END (Program End)'),
            mpatches.Patch(color='#FFD700', label='MERGE (Branch Merge)'),
            mpatches.Patch(color='#87CEEB', label='PROCESS (Normal Block)')
        ]
        plt.legend(handles=legend_elements, loc='upper right', fontsize=12,
                  title="Node Type Description", title_fontsize=14)
        
        # å®Ÿè¡Œé †åºã®èª¬æ˜ã‚’è¿½åŠ 
        info_text = ("Reading Guide:\n"
                    "â€¢ Arrow direction shows execution flow\n"
                    "â€¢ Start from START, end at END\n"
                    "â€¢ PROCESS: sequential processing\n"
                    "â€¢ MERGE: convergence after branching")
        
        plt.text(0.02, 0.98, info_text, transform=plt.gca().transAxes, 
                fontsize=11, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightyellow", alpha=0.8))
        
        plt.axis('off')
        plt.tight_layout()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"execution_flow_{func_name}_{timestamp}.png"
        filepath = os.path.join(self.output_dir, filename)
        
        plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        
        print(f"   âœ… å®Ÿè¡Œãƒ•ãƒ­ãƒ¼å›³ã‚’ä¿å­˜: {filepath}")
        
        # çµ±è¨ˆæƒ…å ±ã®ä¿å­˜
        self.save_analysis_report(func_name, func_obj, cfg, filepath)
        
        plt.close()
    
    def save_analysis_report(self, func_name, func_obj, cfg, image_path):
        """è§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_filename = f"analysis_report_{func_name}_{timestamp}.txt"
        report_filepath = os.path.join(self.output_dir, report_filename)
        
        with open(report_filepath, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write(f"ãƒ—ãƒ­ã‚°ãƒ©ãƒ å®Ÿè¡Œãƒ•ãƒ­ãƒ¼è§£æãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write(f"é–¢æ•°å: {func_name}\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("ğŸ“‹ åŸºæœ¬æƒ…å ±:\n")
            f.write(f"  é–¢æ•°é–‹å§‹è¡Œ: {func_obj.start_line}\n")
            f.write(f"  é–¢æ•°çµ‚äº†è¡Œ: {func_obj.end_line}\n")
            f.write(f"  é–¢æ•°è¡Œæ•°: {func_obj.end_line - func_obj.start_line + 1}\n\n")
            
            f.write("ğŸ“Š åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã‚°ãƒ©ãƒ•çµ±è¨ˆ:\n")
            f.write(f"  ç·ãƒãƒ¼ãƒ‰æ•°: {len(cfg.nodes())}\n")
            f.write(f"  ç·ã‚¨ãƒƒã‚¸æ•°: {len(cfg.edges())}\n")
            
            # ãƒãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
            entry_count = sum(1 for node in cfg.nodes() if hasattr(node, 'is_entrypoint') and node.is_entrypoint)
            exit_count = sum(1 for node in cfg.nodes() if hasattr(node, 'is_exitpoint') and node.is_exitpoint)
            merge_count = sum(1 for node in cfg.nodes() if hasattr(node, 'is_merged_node') and node.is_merged_node)
            regular_count = len(cfg.nodes()) - entry_count - exit_count - merge_count
            
            f.write(f"  ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒãƒ¼ãƒ‰: {entry_count}\n")
            f.write(f"  ã‚¨ã‚°ã‚¸ãƒƒãƒˆãƒãƒ¼ãƒ‰: {exit_count}\n")
            f.write(f"  ãƒãƒ¼ã‚¸ãƒãƒ¼ãƒ‰: {merge_count}\n")
            f.write(f"  é€šå¸¸ãƒãƒ¼ãƒ‰: {regular_count}\n\n")
            
            # è¤‡é›‘åº¦è©•ä¾¡
            complexity = "ä½"
            if len(cfg.nodes()) > 10:
                complexity = "é«˜"
            elif len(cfg.nodes()) > 5:
                complexity = "ä¸­"
            
            f.write(f"ğŸ¯ è¤‡é›‘åº¦è©•ä¾¡: {complexity}\n")
            f.write(f"  ç†ç”±: ãƒãƒ¼ãƒ‰æ•°ãŒ{len(cfg.nodes())}å€‹\n\n")
            
            f.write("ğŸ“ˆ æ¨å¥¨äº‹é …:\n")
            if len(cfg.nodes()) > 15:
                f.write("  - é–¢æ•°ãŒè¤‡é›‘ã™ãã¾ã™ã€‚åˆ†å‰²ã‚’æ¤œè¨ã—ã¦ãã ã•ã„\n")
            elif len(cfg.nodes()) > 10:
                f.write("  - ã‚„ã‚„è¤‡é›‘ã§ã™ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨\n")
            else:
                f.write("  - é©åˆ‡ãªè¤‡é›‘åº¦ã§ã™\n")
            
            f.write(f"\nğŸ“¸ å¯¾å¿œã™ã‚‹å›³: {os.path.basename(image_path)}\n")
        
        print(f"   ğŸ“„ è§£æãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_filepath}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ— ã‚°ãƒ©ãƒ•è¦–è¦šåŒ–ãƒ—ãƒ­ã‚°ãƒ©ãƒ ")
    print("=" * 60)
    print("ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€ã‚³ãƒ¼ãƒ‰ã®å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’åˆ†ã‹ã‚Šã‚„ã™ãè¦–è¦šåŒ–ã—ã¾ã™")
    print("åˆå¿ƒè€…ã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†ã€æ®µéšçš„ã«èª¬æ˜ã‚’è¡Œã„ã¾ã™")
    print("=" * 60)
    
    visualizer = FlowVisualizer()
    
    # è§£æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®é¸æŠ
    available_files = ["whiletest.py"]
    existing_files = [f for f in available_files if os.path.exists(f)]
    
    if not existing_files:
        print("âŒ è§£æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã„ãšã‚Œã‹ã‚’é…ç½®ã—ã¦ãã ã•ã„: {available_files}")
        return
    
    print(f"ğŸ“ åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«:")
    for i, file in enumerate(existing_files, 1):
        print(f"  {i}. {file}")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¾ãŸã¯è‡ªå‹•é¸æŠ
    try:
        choice = input(f"\nè§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ (1-{len(existing_files)}, Enter=å…¨ã¦): ").strip()
        
        if choice == "":
            # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
            for file in existing_files:
                print(f"\n{'='*80}")
                visualizer.analyze_control_flow(file)
        else:
            # æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ
            index = int(choice) - 1
            if 0 <= index < len(existing_files):
                visualizer.analyze_control_flow(existing_files[index])
            else:
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
                return
                
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        return
    except ValueError:
        print("âŒ ç„¡åŠ¹ãªå…¥åŠ›ã§ã™")
        return
    
    print(f"\nâœ… å…¨ã¦ã®è§£æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"ğŸ“ çµæœã¯ä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ:")
    print(f"   {os.path.abspath(visualizer.output_dir)}")
    
    # Windowsãƒ‘ã‚¹è¡¨ç¤º
    windows_path = os.path.abspath(visualizer.output_dir).replace('/mnt/c/', 'C:\\').replace('/', '\\')
    print(f"ğŸªŸ Windowsãƒ‘ã‚¹: {windows_path}")

if __name__ == "__main__":
    main()
