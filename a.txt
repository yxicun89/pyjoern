4 AsanasClusterによるソースコードのクラスタリング
本節では、プログラミング課題に提出された正しいソースコード解答をリアルタイムでクラスタリングするツール「AsanasCluster」の設計と実装を紹介する。この手法は既存技術におけるいくつかの課題を解決する。第一に、高水準な視点からアルゴリズム戦略に基づいてプログラムをグループ化するため、既存のクラスタリング手法の大半よりも少ないクラスタを生成する。次に、プログラムの意味論的グラフ表現から特徴ベクトルを抽出し、
全データセットにわたるグラフ編集距離のような高コストな
ペアワイズ計算を回避します。最後に、増分クラスタリングモデルを採用している。これは、解決策を一度に割り当てるのではなく、システムに投入されるたびにクラスタに割り当てることを意味する。このモデルは、新規観測値に最も近いクラスタを発見する時間を大幅に短縮するだけでなく、提出された解決策に関する最新情報を用いてこのタスクを実行することを可能にする。AsanasClusterのワークフローを図1に示す。
プログラミング課題に対する既存の解法集合Pが与えられた場合、
入力として受け取った各新規プログラムpに対して、
既存のKotlinライブラリ[13]を応用した手法を用いて
EOGとDFGの両方を生成する。この手法はソースコードから
コードプロパティグラフ（必要な表現を含む）を抽出するよう設計されており、
Python、Java、C、C++で記述されたプログラムのサポートを保証する。得られたEOGは、エッジ収縮を含むプロセスを通じてCFGに変換される。すなわち、送信元のアウトディグリーが1かつ宛先のインディグリーが1であるすべてのエッジが収縮される。これらの最終表現であるDFGとCFGを分析し、プログラムの特徴ベクトルを構成する制御フローとデータフローの特徴を計算する（詳細は4.1節で説明する）。最終的に得られた特徴ベクトルは、実装されたk-meansクラスタリングアルゴリズムに入力される（詳細は4.1節参照）。

4.1 特徴量エンジニアリング
提案手法の重要な特徴は、使用するプログラムの表現方法にある。クラスタリング処理は、アルゴリズム戦略、すなわち問題を解決または関数を計算するために明確に定義された順序で実行される命令列によってソースコードソリューションを分離することを目的とする。
プログラムの実行フロー、すなわち命令が実行される順序は、したがってアルゴリズム戦略の本質的な側面である。これと命令間のデータ依存関係に関する知識を組み合わせることで、アルゴリズム戦略はほぼ網羅される[12]。前者の情報はCFG（またはEOG）によって捕捉され、後者はDFGに符号化される（3.1節および3.3節で説明）。
これらの表現を得るため、我々はまずPython、Java、C、C++で記述されたソースコードからコードプロパティグラフ（CPG）[48]を抽出するために開発されたKotlinライブラリ[13]を適応させた。CPGはAST、DFG、EOGを統合したデータ構造であり、セキュリティ脆弱性を表すプログラミングパターンを大規模コードベースから抽出するために設計されている。
この表現には必要な情報が含まれているため、
我々の適応は、CPGをカンマ区切り値（CSV）形式でエクスポートする機能をライブラリに追加することである。
エクスポートされる成果物は2つのCSVファイルで構成される：
1つはノードの説明（ID、構文要素の種類、トークン、位置を含む）を、
もう1つはエッジの説明（ソース、位置、起源（AST、EOG、またはDFG）を含む）を記述する。
後者には特定の起源に関する追加情報（例：DFGのエッジに対する変数識別子）も含まれる。EOGとCFGはいずれもプログラムの制御フローを表現しますが、
後者はグラフサイズが大幅に小さくなります。したがって、
さらなる計算を行う前に、得られたEOGはエッジ収縮プロセスを通じて
CFGに変換されます。具体的には、始点のアウトディグリーが1かつ
終点のインディグリーが1であるエッジをすべて収縮します。
CFGとDFGによるクラスタリングには、全データセットにおける2つのペアワイズグラフ編集距離の測定が必要となる。
これらは複雑な操作であり、計算コストはグラフとデータセットのサイズに比例して指数関数的に増加する。したがって、
我々のアプローチはむしろ特徴量ベースである。CFGとDFGの両グラフの特徴から計算された数値で構成される特徴ベクトルを導出する。

このベクトルは11の特徴量を含み、具体的には以下の通りである：connected_components、制御フローグラフ内の連結成分の数（すなわち、手続き内表現であるため、複数の手続きはグラフ内で接続されていない）；loop_statements、プログラム内のループ文（例：for、foreach、while、do...while）の数；
conditional_statements：プログラム内の条件文（例：if）の数；cycles：制御フローグラフ内の異なるループの数；paths：制御フローグラフ内の異なるパス数；cyclomatic_complexity：制御フローを分析してプログラムの複雑さを測定するソフトウェアメトリクス（プログラム内の可能な実行パスの数を定量的に評価）； variable_count：プログラムで使用される変数の数（読み込まれない変数は除く）；
total_reads：変数に対する読み取り操作の総数；
total_writes：変数に対する書き込み操作の総数；
max_reads：単一変数に対する最大読み取り操作数；
max_writes：単一変数に対する最大書き込み操作数。
表1はモデルの特性をまとめたものである。
命令の実行順序が解法のアルゴリズム戦略において最も重要であるため、データフロー特性の重みを分割することを決定した。このうち変数使用数（variable_count）は定義上他の特性に依存するため、より大きな重みを持つ。これら全特性の合計重みは単一の制御フロー特性と同等である。さらに、データを平均0・分散1に正規化している。このため、各特徴量ごとに実行平均と分散を維持する。増分処理のため正確な平均・分散は事前には不明だが、長期的に悪影響はない。
モデル内の特徴量数が多すぎると管理が困難になり、冗長な特徴量がノイズを加える可能性もある。これを防ぐため、当モデルの11特徴量間の相関を
PROGpediaデータセット[36]の16プログラミング演習に対し
ピアソンの相関係数[23]を用いて測定しました。相関係数は
−1から1の範囲で値を取ります：0に近い値は弱い相関（つまり0は相関なし）を示し、
1に近づくほど強い正の相関を示し、−1に近づくほど強い負の相関を示します。各プログラミング演習は個別に分析され、相関が0.9を超えるペアに対して投票を行います。総投票数の半分以上を獲得したペアについては、そのメンバーが排除されます。ただし、今回のケースでは、これらの条件を満たす相関ペアは特定されませんでした。

4.2 クラスタリングモデル
最終特徴ベクトルの値は、実装されたk-meansクラスタリングアルゴリズム（3.4節参照）への入力として与えられる。この実装では、ガウス分布に従ってk個の重心点をランダムに初期化する。kの値はモデルの主要なハイパーパラメータであり、形成されるクラスタ数の上限を設定する。目標はアルゴリズム的解決策の数と同数のクラスターを形成することであるため、適切な値は異なる解決策の予想数以上となる。学術レベルのプログラミング課題で16を超えるアルゴリズム的解決策が存在することは無視できるため、クラスターの最大数は16に制限した。ただしこの値は課題ごとに明示的に定義可能である。
新規提出物（より正確にはそこから抽出された特徴ベクトル）に対し、まず最も近い中心点を特定する。これは特定の距離測定法を用いて新規観測値から各中心点までの距離を測定し、それらの最小値を選択することで実現される。本研究では、明確なアルゴリズム的解決策を持つプログラミング課題の提出物群に対し、
マンハッタン距離、ユークリッド距離、コサイン距離の3種を試行した。ユークリッド距離はマンハッタン距離（0.3）やコサイン距離（0.25）よりも低い平均誤差指数（0）を示したため、本手法を採用した。新規観測値が属する重心（およびクラスター）を特定した後、その重心位置は新規要素の方向へ「移動」する。中心点を移動させる量は、
それらのスカラー距離と学習率の積である。
学習率は、プロセス中にクラスターに割り当てられた
解の数の逆数であり、つまり要素数が増加するにつれ、
新規要素の影響は減少する。
このクラスタリング処理の擬似コードはアルゴリズム1に示す。特徴ベクトルが解オブジェクトとして提供されることを前提としており、グラフ表現の抽出やそれに続く特徴ベクトル値の計算は省略する。さらに、重心点が「移動」する際には、既存の解に対して最も近い重心点を再特定する。

4.3 Mooshak との統合
AsanasCluster は自動評価エンジンへの統合を目指し、
提出データ（オフライン：過去に提出された解答／リアルタイム：システムに新規入力される解答）を
消費する。この目的のため、AsanasCluster は二つのモードを備える。
一つは特定のプログラミング課題に対する全既存提出物からクラスタリングモデルを構築する。
もう一つは、ディスクに保存されたクラスタリングモデルを読み込み、
与えられた提出物に最も近いクラスタを特定し、それが承認済み解答である場合にモデルに含める。
Mooshak [25] は自動評価機能を提供する既存システムの一つであり、AsanasClusterの開発・テストに選定された。Mooshakはファイルシステムをオブジェクトデータベースとして利用し、ディレクトリ構造で整理されたTclコードファイル内にデータを保存・取得する。したがって、提出物のメタデータはソースコードやCPGの抽出CSVファイルと共に提出フォルダ内に保存される。
クラスタリングモデル構築のため、AsanasClusterは
提出物のディレクトリを単純に反復処理し、各提出フォルダについて
CPGを読み込み、モデルに処理する（受理された場合）。新規提出物がシステムに入ると、
AsanasClusterはMooshakの最終評価者として機能し、
提出物をモデルに追加するとともに、
前評価者の分類結果を出力します。
提出物が却下分類の場合、
最も近いクラスターの識別情報も出力され、
モデル更新は破棄されます。


5 評価
本節では、プログラミング課題の自動評価におけるAsanasClusterの精度と時間的妥当性に関する評価結果を示す。この目的のため、我々は公開コレクションであるPROGpedia [36]（2003年から2020年までの複数年にわたり、学部コンピュータサイエンスコースのMooshak [25]上で実施された16のプログラミング課題に提出されたソースコード）を用いてクラスタリングの性能を評価した。データセットは合計9117件の提出物で構成される。
クラスタリング出力をプログラム修復ツールの入力として利用することを意図しているため、提出物をプログラミング演習ごとに分類するだけでなく、プログラミング言語ごとに分離した。C/C++（C17）、Java（Java 8）、Python（バージョン3）で記述されたソリューションのみを対象とした（注：括弧内のバージョンは「互換性がある」ことを意味し、完全一致ではない）。
全テストはDell XPS 15 9570上で実行。

5.1 実行時間
本研究の目的は、プログラミング課題の自動評価における中間ステップとしてAsanasClusterを活用することである。
プログラミング課題の自動評価に関する文献では単一評価の時間制限は正式に定義されていないが、ほぼリアルタイムを意図するタスクには1分が妥当な上限である[1]。AsanasClusterのスケーラビリティを評価するため、以下の処理に要する時間を計測した：(1)過去の提出課題からクラスタリングモデルを新規構築する時間、(2)新規の正解ソリューションを発見する時間、
(3) 新規提出された解答のクラスター判定に要する時間を計測した。(1)については、PROGpedia [36]の正解解答セットに対し、プログラミング演習と言語別にデータを分離した上でモデルを構築した。表2は提出物に関するデータセットの構成をまとめ、
各課題/プログラミング言語ペアごとの提出数と
平均コード行数を示す。(2)では新たな正解ソリューションを開発した。
最後に(3)では誤った試行を無作為に選択する。
提出物セットに対するクラスタリングモデルの構築（1）には
4つのステップが必要である。第一に、課題への全提出物を格納する
ディレクトリから適切な解答（すなわち、モデルの言語で記述された
受理済み解答）を検索・選択する。第二に、必要な意味的グラフ表現、
すなわちDFGとCFGを生成する。第三に、これらの表現から特徴ベクトルを
計算する。
最後に、既存の観測値を処理してk-meansモデルを構築する。
表3は、各ペア（プログラミング課題、プログラミング言語）について、
解の集合のサイズ、構築時間、生成されたクラスター数を示す。
モデルの構築に要する最大時間は、
グラフ探索アルゴリズムの実装を必要とする
プログラミング課題53への152件のJava提出物に対して
9分30秒である。予想通り、プログラミング言語や課題の複雑度に比べ、
提出数の多さが学習性能に最も大きな影響を与える。
ただし、解の複雑さも実行時間に悪影響を及ぼす。
例えば数値ベクトルのソートを要求する課題34の
205件の提出を処理する時間は、課題53の152件に比べ
9秒未満である。
生成されたクラスター数は、提出数やプログラミング言語のいずれとも顕著な相関関係を示さない。構築されたモデルの中央値クラスター数は4である。演習42のC言語で記述された解の集合は9クラスターを有し、評価対象集合中で最も高いクラスター数を示した。表4は構築済みモデルを用いた(2)新規解のモデルへの処理時間と(3)新規提出解に対する最適クラスターの特定時間を示す。平均して、学習には5,397秒、新規観測値のクラスター予測には4,910秒を要する。7秒以上かかるタスクは存在しない（最悪ケースは6,981秒）。

5.2 エラー指標
本分析は、AsanasClusterが実装された異なるアルゴリズム戦略を
ソリューション内で分離する有効性を検証することを目的とする。
この目的のため、我々は単純な指標(1)を採用し、これをエラー指標と命名した。
エラー指標は0から1の値を取り、0は全てのソリューションが
正しくグループ化されたことを示す。ある解が誤ってグループ化されているとみなされるのは、
異なる戦略のクラスター（すなわち、そのクラスターに
属する解が最も多いアルゴリズム戦略）に含まれている場合である。
この指標は、同じアルゴリズム戦略を採用する解が
異なるクラスターに分散しているケースを意図的に無視する。
その理由は、それらの解が依然としてかなり異なる可能性があることを
理解しているためである。
エラー指数 = 誤ってグループ化された解の数
解の数
(1)
これを評価するため、2つの別々のタスクを実施する。最初のタスクでは、2つのグラフ探索アルゴリズム（深さ優先探索50、幅優先探索50）の異なる実装100件をクラスタリングする。これらのプログラムはアルゴリズム設計と解析の授業中に収集されたものである。
2番目のタスクでは、GitHubから収集したソートアルゴリズム（ヒープソート、マージソート、挿入ソート）を実装する100件のプログラムをクラスタリングする。



5.2 エラー指標
本分析は、AsanasClusterがソリューションに実装された異なるアルゴリズム戦略を分離する有効性を検証することを目的とする。この目的のために、我々はエラー指標と名付けた単純な指標(1)を考慮する。エラー指標は0から1の値を取り、0は全てのソリューションが正しくグループ化されたことを示す。ある解が誤ってグループ化されているとみなされるのは、
異なる戦略のクラスター（すなわち、そのクラスターに
最も多くの解が属するアルゴリズム戦略）に含まれている場合である。
この指標は、同じアルゴリズム戦略を採用する解が
異なるクラスターに分散しているケースを意図的に無視する。
その理由は、それらの解が依然としてかなり異なる可能性があることを
理解しているためである。
誤分類指数 = 誤分類された解の数
解の総数
(1)
これを評価するため、2つの別々のタスクを実施する。最初のタスクでは、2種類のグラフ探索アルゴリズム（深さ優先探索50、幅優先探索50）の異なる実装100件をクラスタリングする。これらのプログラムはアルゴリズム設計と解析の授業中に収集されたものである。
第二のタスクでは、GitHubから収集した100のソートアルゴリズム実装プログラム（ヒープソート、マージソート、挿入ソート、クイックソート）をクラスタリングする。各ソートアルゴリズムにつき25サンプルが存在する。
図2は、両タスクの結果得られたクラスターの2成分主成分分析（PCA）可視化を示す。（左図では主成分1と2がそれぞれ変動の83%と6%を説明し、右図では60%と24%を説明している。）赤い十字はクラスターの中心点を示す。左図では4つのクラスターが確認できる。緑のクラスターには深さ優先探索の実装に対応する50点が含まれる。
幅優先探索の実装は灰色のクラスターに割り当てられている。
右側では、4つのクラスターが異なるソートアルゴリズムに対応している：挿入ソート（灰色）、ヒープソート（緑）、クイックソート（青）、マージソート（黄色）。特徴ベクトルの値が同一（または極めて近似）なため、一部のデータ点は可視化されていません。両実験において、異なるアルゴリズム戦略に対応するクラスターが各1つ存在し、解はこれらのクラスターによって均等に分割されています。さらに、異なるアルゴリズム戦略の解を含むクラスターが存在しないため、両タスクのエラー指数は0と評価されます。
第2タスクの集合に基数ソートアルゴリズムの実装を1つ追加しても、エラー指数は変化しない。図3の2成分PCA可視化（PC1とPC2がそれぞれ変動の61%と23%を説明する）が示すように、この新規解により新たなクラスター（青）が生成される一方、既存クラスターは変化しない。
しかし、選択ソートアルゴリズムの実装を数件追加すると誤差指数が増加する。その実装は挿入ソートと意味的に類似しているため、新規クラスターを形成する十分なサンプル数が集まるまでは両者が同一クラスターに割り当てられる。例えば3件の実装を追加すると誤差指数は0.03（103件中3件の誤分類）となる。
意図的または偶発的に提出された無関係な解を
AsanasClusterがどのように扱うかを示すため、
ソートアルゴリズムのクラスタリングモデルに
幅優先探索の実装を追加した。結果は図4の2成分PCA可視化で示される（PC1とPC2はそれぞれ変動の63%と21%を説明する）。無関係な解は新たなクラスター（灰色領域）に隔離され、他のクラスターは影響を受けない。したがって誤差指数は0となる。



5.3 考察
文献には、本論文で説明したものと同等のクラスタリング手法を導入するツールがいくつか存在する。具体的にはSemCluster [37]、OverCode [14]、CLARA [17]である。SemClusterの評価には、後述のツール（OverCodeとCLARA）との比較が含まれる。表2で言及されているような小規模な実装間での類似性計算は短時間で実行可能だが、新規解のクラスタリングには、新規解と既存解の全ペア間の比較が必要となる。SemClusterの評価は、これが各手法の実行時間に
多大な影響を与えることを示している（例：CLARAツールは
100行未満のプログラムでも100分以上かかる場合がある）。
SemClusterは既存ツール[37]よりも優れた実行時間性能と精度を
示し、異なるアルゴリズム的解決戦略を識別する。
しかしながら、提案手法はいずれも増分的ではなく、
つまり新規提出ごとにクラスタリングモデルの再構築を要する。
これは分析対象ツールのいずれにおいても、
50行未満の小型プログラムであっても
1分以上を要する。
モデル学習セッション間でソースコード表現が保存されると仮定しても、
SemClusterはモデル再計算（要素追加時）に要する平均時間の中央値が18秒、
最大30秒に達する可能性がある。
[37]で使用されたデータセットが入手不可能であるため、本論文で記述する実行時間性能の評価では、同一の課題に対して異なる公開データセット[36]を用いてツールを適用した。このデータセットには、学部生向けコンピュータサイエンス科目の複数段階で提供される、複雑さが異なる16の課題が含まれており、C、C++、Java、Pythonで実装された複数の異なるアルゴリズムを使用している。本データの構成は表2に示す通り、[37]で使用されたデータとかなり類似している。この条件下で、当ツールは新規解法のクラスターを特定しモデルに統合する際に、中央値で4秒（Python）および5秒（C/C++/Java）の実行時間を要する。最悪ケースでは最大7秒かかる。
異なるアルゴリズム的解決戦略の識別精度に関して、
SemClusterは2つのタスクで有効性を実証した。
第一に、ソートアルゴリズムを用いた割り当て問題の
100解を、採用アルゴリズム（バブルソート、
クイックソート、特定なし（2クラスター））に基づき
4クラスターに分離することに成功した。最後に、適用された探索アルゴリズム（深さ優先探索と幅優先探索）に基づき、100のプログラムを2つのクラスターに完全に分割できました。同様に、AsanasClusterを評価するための実験も、5.2節で説明されているように、2つのタスクで最適な結果を達成しました。
したがって、プログラミング課題の自動評価プロセスへの組み込みを考慮すると、AsanasClusterは文献で提示されている最も類似したツールよりも優れた性能を発揮できる。しかしながら、主な利点は(1)特徴ベクトル抽出のためのコード実行を必要としないこと、(2)わずか2件の提出データからクラスタリングプロセスを開始し、クラスタを再計算できることである。


5.4 有効性に対する脅威
SemCluster [37] との直接比較（すなわち同一データセットの使用）によってのみ、アルゴリズム戦略の分離における実行時間と精度に関して、最先端技術の改善を実証できる。残念ながら、データセットもツールも公開されておらず、著者への要請によっても提供されなかった。ただし、
コード行数を考慮し、平均的にさらに大規模な解決策を
いくつか含む、同程度の複雑なデータセットの選択を
試みた。
さらに、入門的なプログラミング課題で典型的に見られる
中小規模のプログラムに対して本手法を評価した。
これは関連研究と一致するが、今後の研究では、
より高度なコースで見られる大規模プログラムへの
本手法の拡張を検証することを目指す。
